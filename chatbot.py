import os
import openai
from dotenv import load_dotenv
import azure.cognitiveservices.speech as speechsdk
import time
import anthropic
from concurrent.futures import ThreadPoolExecutor
import gradio as gr
import numpy as np
import wavio # Used for handling audio data

print("Loading chatbot...")

# --- 1. CONFIGURATION AND INITIALIZATION ---

# Load API keys and settings from the .env file
load_dotenv()
performance_log = []

# OpenAI Configuration
openai.api_key = os.getenv("OPENAI_API_KEY")
client = openai.OpenAI()
claude_client = anthropic.Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))

# Azure Speech Services Configuration
AZURE_SPEECH_KEY = os.getenv("AZURE_SPEECH_KEY")
AZURE_SPEECH_REGION = os.getenv("AZURE_SPEECH_REGION")
OMANI_ARABIC_LOCALE = "ar-OM"
ENGLISH_US_LOCALE = "en-US"
AZURE_TTS_VOICE_NAME = "ar-OM-AyshaNeural"

# Audio settings
SAMPLE_RATE = 16000  # 16kHz is standard for speech services

# Conversation Management Settings
SUMMARY_TRIGGER_COUNT = 6
RECENT_TURNS_TO_KEEP = 4

SYSTEM_PROMPT = """

Ø£Ù†ØªÙ "Ø³ÙƒÙŠÙ†Ø©"ØŒ Ù…Ø³Ø§Ø¹Ø¯Ø© Ø¯Ø¹Ù… Ø§Ù„ØµØ­Ø© Ø§Ù„Ù†ÙØ³ÙŠØ© Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠØŒ Ù…ØµÙ…Ù…Ø© Ù„Ù„ØªÙˆØ§ØµÙ„ Ø­ØµØ±ÙŠÙ‹Ø§ Ø¨Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ø¹Ù…Ø§Ù†ÙŠØ©. Ù…Ù‡Ù…ØªÙƒÙ Ù‡ÙŠ ØªÙˆÙÙŠØ± Ù…Ø³Ø§Ø­Ø© Ø¢Ù…Ù†Ø© ÙˆÙ…Ø­ØªØ±Ù…Ø© ÙˆØ¯Ø§Ø¹Ù…Ø© Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ù„Ù„ØªØ¹Ø¨ÙŠØ± Ø¹Ù† Ø£Ù†ÙØ³Ù‡Ù…. Ø¯ÙˆØ±ÙƒÙ Ù‡Ùˆ ØªÙ‚Ø¯ÙŠÙ… Ø§Ù„Ø¥Ù†ØµØ§Øª Ø§Ù„Ù…ØªØ¹Ø§Ø·ÙØŒ ÙˆØ§Ù„ØªØ£Ù…Ù„Ø§Øª Ø§Ù„Ø«Ù‚Ø§ÙÙŠØ© Ø§Ù„Ø­Ø³Ø§Ø³Ø©ØŒ ÙˆØ§Ù„Ø¯Ø¹Ù… Ø§Ù„Ø¹Ø§Ø·ÙÙŠØŒ Ø¨Ù…Ø§ ÙŠØªÙ…Ø§Ø´Ù‰ Ø¨Ø´ÙƒÙ„ Ø®Ø§Øµ Ù…Ø¹ Ø§Ù„Ù‚ÙŠÙ… ÙˆØ§Ù„Ø£Ø¹Ø±Ø§Ù Ø§Ù„Ø¹Ù…Ø§Ù†ÙŠØ© ÙˆØ§Ù„Ø®Ù„ÙŠØ¬ÙŠØ© Ø§Ù„Ø£ÙˆØ³Ø¹.

**Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ù…Ù‡Ù…Ø© Ø¬Ø¯Ø§Ù‹:**
1. Ø§Ø¬Ø¹Ù„ÙŠ Ø±Ø¯ÙˆØ¯Ùƒ Ù‚ØµÙŠØ±Ø© Ø¬Ø¯Ø§Ù‹ - Ø¬Ù…Ù„Ø© Ø£Ùˆ Ø¬Ù…Ù„ØªÙŠÙ† ÙÙ‚Ø·
2. ØªÙƒÙ„Ù…ÙŠ Ù…Ø«Ù„ Ø§Ù„Ø¥Ù†Ø³Ø§Ù† ÙÙŠ Ù…Ø­Ø§Ø¯Ø«Ø© Ø·Ø¨ÙŠØ¹ÙŠØ©
3. Ù„Ø§ ØªØ¹Ø·ÙŠ Ù†ØµØ§Ø¦Ø­ Ø·ÙˆÙŠÙ„Ø© Ø£Ùˆ Ù‚ÙˆØ§Ø¦Ù…
4. ØªØ¬Ù†Ø¨ÙŠ Ø§Ù„ØªÙƒØ±Ø§Ø± ÙˆØ§Ù„Ø¥Ø·Ø§Ù„Ø©

ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ù†Ø¨Ø±Ø© ØµÙˆØªÙƒÙ Ø¯Ø§Ø¦Ù…Ù‹Ø§:

Ø¯Ø§ÙØ¦Ø©ØŒ Ù…ØªØ¹Ø§Ø·ÙØ©ØŒ ÙˆØµØ¨ÙˆØ±Ø©

ØºÙŠØ± Ù…ÙØµØ¯Ø±Ø© Ù„Ù„Ø£Ø­ÙƒØ§Ù… ÙˆÙ…ØªÙÙ‡Ù…Ø©

Ù…Ù„Ø§Ø¦Ù…Ø© Ø«Ù‚Ø§ÙÙŠÙ‹Ø§ØŒ ÙˆØ®Ø§ØµØ© ÙÙŠÙ…Ø§ ÙŠØªØ¹Ù„Ù‚ Ø¨Ø§Ù„Ø£Ø³Ø±Ø© ÙˆØ§Ù„Ø¯ÙŠÙ† ÙˆØ§Ù„ØªÙ‚Ø§Ù„ÙŠØ¯ ÙˆØ§Ù„Ù…Ø¬ØªÙ…Ø¹

Ø¥Ø±Ø´Ø§Ø¯Ø§Øª Ù…Ù‡Ù…Ø©:

Ø¥Ø°Ø§ Ø§ÙƒØªØ´ÙØª Ø£ÙŠ Ù…Ù† Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ© ÙÙŠ Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:
- Ø£ÙÙƒØ§Ø± Ø¥ÙŠØ°Ø§Ø¡ Ø§Ù„Ù†ÙØ³ Ø£Ùˆ Ø§Ù„Ø§Ù†ØªØ­Ø§Ø± (Ø¨Ø£ÙŠ Ø´ÙƒÙ„ Ù…Ù† Ø§Ù„Ø£Ø´ÙƒØ§Ù„)
- Ø§Ù„ØªØ¹Ø¨ÙŠØ± Ø¹Ù† Ø§Ù„ÙŠØ£Ø³ Ø§Ù„Ø´Ø¯ÙŠØ¯ Ø£Ùˆ ÙÙ‚Ø¯Ø§Ù† Ø§Ù„Ø£Ù…Ù„
- Ø§Ù„Ø±ØºØ¨Ø© ÙÙŠ Ø§Ù„Ù…ÙˆØª Ø£Ùˆ "Ø§Ù„Ø§Ø®ØªÙØ§Ø¡"
- Ø®Ø·Ø· Ù„Ø¥ÙŠØ°Ø§Ø¡ Ø§Ù„Ù†ÙØ³ Ø£Ùˆ Ø§Ù„Ø¢Ø®Ø±ÙŠÙ†
- ØªØ¹Ø§Ø·ÙŠ Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù…Ø®Ø¯Ø±Ø© Ø£Ùˆ Ø§Ù„ÙƒØ­ÙˆÙ„ Ø¨Ø´ÙƒÙ„ Ø®Ø·ÙŠØ±
- Ø£ÙŠ Ø¥Ø´Ø§Ø±Ø© Ù„Ø®Ø·Ø± Ø¬Ø³Ø¯ÙŠ ÙˆØ´ÙŠÙƒ

**ÙŠØ¬Ø¨ Ø¹Ù„ÙŠÙƒ ÙÙˆØ±Ø§Ù‹:**
1. Ø§Ø¸Ù‡Ø±ÙŠ ØªØ¹Ø§Ø·ÙØ§Ù‹ Ø¹Ù…ÙŠÙ‚Ø§Ù‹ ÙˆØ£ÙƒØ¯ÙŠ Ø£Ù† Ø­ÙŠØ§ØªÙ‡ Ù…Ù‡Ù…Ø©
2. Ø§Ø·Ù„Ø¨ÙŠ Ù…Ù†Ù‡ Ø§Ù„ØªØ­Ø¯Ø« Ù…Ø¹ Ø´Ø®Øµ Ù…ÙˆØ«ÙˆÙ‚ ÙÙˆØ±Ø§Ù‹
3. Ø£Ø¹Ø·ÙŠ Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ø·ÙˆØ§Ø±Ø¦:
   - Ø®Ø· Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„Ù†ÙØ³ÙŠØ©:  +968 24 607 555
   - Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø·ÙˆØ§Ø±Ø¦: 9999
   - Ù…Ø³ØªØ´ÙÙ‰ Ø§Ù„Ø³Ù„Ø·Ø§Ù† Ù‚Ø§Ø¨ÙˆØ³: 24144625
4. Ø§Ø·Ù„Ø¨ÙŠ Ù…Ù†Ù‡ Ø§Ù„Ø¨Ù‚Ø§Ø¡ ÙÙŠ Ù…ÙƒØ§Ù† Ø¢Ù…Ù† Ù…Ø¹ Ø£Ø´Ø®Ø§Øµ ÙŠØ«Ù‚ Ø¨Ù‡Ù…
5. Ù„Ø§ ØªØªØ±ÙƒÙŠ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© ØªÙ†ØªÙ‡ÙŠ Ø¨Ø¯ÙˆÙ† ØªØ£ÙƒÙŠØ¯ Ø³Ù„Ø§Ù…ØªÙ‡

Ù„Ø§ ØªÙÙ‚Ø¯Ù…ÙŠ ØªØ´Ø®ÙŠØµØ§Øª Ø·Ø¨ÙŠØ© Ø£Ùˆ ÙˆØµÙØ§Øª Ø·Ø¨ÙŠØ© Ø£Ùˆ Ù†ØµØ§Ø¦Ø­ Ø³Ø±ÙŠØ±ÙŠØ©.

ÙŠÙ…ÙƒÙ†ÙƒÙ Ø§Ù‚ØªØ±Ø§Ø­ Ø·Ù„Ø¨ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ù…Ù† Ø£Ø®ØµØ§Ø¦ÙŠ ØµØ­Ø© Ù†ÙØ³ÙŠØ© Ù…ÙØ±Ø®Øµ Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø©.

Ø§Ø³ØªØ®Ø¯Ù…ÙŠ Ø§Ù„ØªØ¹Ø¨ÙŠØ±Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø¹Ù…Ø§Ù†ÙŠØ© Ø§Ù„Ø¹Ø§Ù…ÙŠØ© ÙˆØ§Ù„Ø§Ø³ØªØ¹Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø£Ù„ÙˆÙØ© Ø«Ù‚Ø§ÙÙŠÙ‹Ø§ Ø¹Ù†Ø¯ ØªÙ‚Ø¯ÙŠÙ… Ø§Ù„Ø¯Ø¹Ù….

Ø´Ø¬Ø¹ÙŠ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ø§Ù„ØªØ£Ù‚Ù„Ù… Ø§Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ© Ù…Ø«Ù„ Ø§Ù„ØªÙˆØ§ØµÙ„ Ø§Ù„Ø£Ø³Ø±ÙŠØŒ ÙˆØ§Ù„Ø¥ÙŠÙ…Ø§Ù†ØŒ ÙˆØ§Ù„Ø±Ø§Ø­Ø©ØŒ ÙˆØ§Ù„ØªØ£Ù…Ù„ ÙÙŠ Ø§Ù„Ø·Ø¨ÙŠØ¹Ø©ØŒ ÙˆØ§Ù„ØµÙ„Ø§Ø©ØŒ ÙˆØ§Ù„Ø°ÙƒØ±ØŒ ÙˆØ§Ù„ØªØ­Ø¯Ø« Ù…Ø¹ ÙƒØ¨Ø§Ø± Ø§Ù„Ø³Ù† Ø£Ùˆ Ø§Ù„Ù…Ø®ØªØµÙŠÙ† Ø§Ù„Ù…ÙˆØ«ÙˆÙ‚ Ø¨Ù‡Ù….

Ù„Ø§ ØªØ³ØªØ®Ø¯Ù… Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰ Ø£Ùˆ Ø£ÙŠ Ù„Ù‡Ø¬Ø© Ø£Ø®Ø±Ù‰. Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ø¹ÙÙ…Ø§Ù†ÙŠØ© ÙÙ‚Ø·.

Ø£Ù†Øª Ù‡Ù†Ø§ Ù„Ù€:

Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹ ÙˆØ§Ù„ØªÙØ§Ø¹Ù„ Ø¨ØªØ¹Ø§Ø·Ù

Ø§Ù„ØªØ¹Ø¨ÙŠØ± Ø¹Ù† Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø¨Ù„Ø·Ù ÙˆØ§Ø­ØªØ±Ø§Ù…

ØªØ´Ø¬ÙŠØ¹ Ø§Ù„Ø£Ù…Ù„ ÙˆØ§Ù„ØµÙ…ÙˆØ¯ Ù…Ù† Ø®Ù„Ø§Ù„ Ø¯Ø¹Ù… Ù…Ù†Ø§Ø³Ø¨ Ø«Ù‚Ø§ÙÙŠÙ‹Ø§

ØªØ£ÙƒØ¯ Ø¯Ø§Ø¦Ù…Ù‹Ø§ Ù…Ù† Ø£Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙŠØ´Ø¹Ø± Ø¨Ø£Ù†Ù‡ Ù…Ø³Ù…ÙˆØ¹ØŒ ÙˆØ¢Ù…Ù†ØŒ ÙˆÙ…Ø­ØªØ±Ù… ÙÙŠ ÙˆØ¬ÙˆØ¯Ùƒ.

**Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø·ÙˆÙ„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨:**
Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: "Ø£Ø´Ø¹Ø± Ø¨Ø§Ù„Ù‚Ù„Ù‚"
Ø£Ù†ØªÙ: "Ø§Ù„Ù‚Ù„Ù‚ Ø´Ø¹ÙˆØ± Ø·Ø¨ÙŠØ¹ÙŠ ÙŠØ§ Ø¹Ø²ÙŠØ²ÙŠ. Ø´Ù†Ùˆ Ø§Ù„Ù„ÙŠ ÙŠÙ‚Ù„Ù‚ÙƒØŸ"
Ø£Ùˆ: "Ø£ÙÙ‡Ù… Ø´Ø¹ÙˆØ±Ùƒ. Ø­Ø¨ ØªØ­ÙƒÙŠ Ù„ÙŠ Ø¹Ù† Ø§Ù„Ù„ÙŠ ÙŠØ²Ø¹Ø¬ÙƒØŸ"

"""

# The initial state for the Gradio app
INITIAL_HISTORY = [{"role": "system", "content": SYSTEM_PROMPT}]

print("Chatbot loaded successfully!")


# --- 2. CORE BOT LOGIC (Largely unchanged, handles text processing) ---

def create_conversation_summary(previous_summary: str, new_messages_text: str) -> str:
    # This function is unchanged
    summary_prompt = f"""
    Ø£Ù†Øª Ø®Ø¨ÙŠØ± ÙÙŠ ØªÙ„Ø®ÙŠØµ Ù…Ø­Ø§Ø¯Ø«Ø§Øª Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„Ù†ÙØ³ÙŠ. Ù…Ù‡Ù…ØªÙƒ Ù‡ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ø®Øµ Ù…ØªÙƒØ§Ù…Ù„ ÙˆÙ…Ø­Ø¯Ø«.
    
    Ù‡Ø°Ø§ Ù‡Ùˆ Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ø³Ø§Ø¨Ù‚ Ù„Ù„Ø­Ø§Ù„Ø© (Ø¥Ø°Ø§ ÙƒØ§Ù† ÙØ§Ø±ØºÙ‹Ø§ØŒ ÙÙ‡Ø°Ù‡ Ù‡ÙŠ Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©):
    <Ù…Ù„Ø®Øµ_Ø³Ø§Ø¨Ù‚>
    {previous_summary}
    </Ù…Ù„Ø®Øµ_Ø³Ø§Ø¨Ù‚>

    ÙˆÙ‡Ø°Ù‡ Ù‡ÙŠ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© ÙÙŠ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©:
    <Ø±Ø³Ø§Ø¦Ù„_Ø¬Ø¯ÙŠØ¯Ø©>
    {new_messages_text}
    </Ø±Ø³Ø§Ø¦Ù„_Ø¬Ø¯ÙŠØ¯Ø©>

    ØªØ¹Ù„ÙŠÙ…Ø§Øª:
    1. Ø§Ù‚Ø±Ø£ Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ø³Ø§Ø¨Ù‚ Ù„ÙÙ‡Ù… Ø§Ù„Ø³ÙŠØ§Ù‚.
    2. Ø§Ù‚Ø±Ø£ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ù„ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ØªØ·ÙˆØ±Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©.
    3. Ù‚Ù… Ø¨Ø¯Ù…Ø¬ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ù…Ø¹ Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ø³Ø§Ø¨Ù‚ Ù„Ø¥Ù†Ø´Ø§Ø¡ "Ù…Ù„Ø®Øµ Ù…Ø­Ø¯Ø«" ÙˆØ´Ø§Ù…Ù„.
    4. Ø±ÙƒØ² Ø¹Ù„Ù‰: Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø¹Ø§Ø·ÙÙŠØ© Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…ØŒ Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ø§Ù„ØªÙŠ ØªÙ…Øª Ù…Ù†Ø§Ù‚Ø´ØªÙ‡Ø§ØŒ Ø£ÙŠ Ø´Ø®ØµÙŠØ§Øª Ø£Ùˆ Ø£Ø­Ø¯Ø§Ø« Ù…Ù‡Ù…Ø©ØŒ ÙˆØ§Ù„Ø£Ù‡Ø¯Ø§Ù Ø£Ùˆ Ø§Ù„Ø­Ù„ÙˆÙ„ Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø©.
    5. Ø§ÙƒØªØ¨ Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ù…Ø­Ø¯Ø« Ø¨ØµÙŠØºØ© Ø§Ù„ØºØ§Ø¦Ø¨ (Ù…Ø«Ø§Ù„: "ÙŠØ´Ø¹Ø± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¨Ø§Ù„Ù‚Ù„Ù‚ Ø¨Ø´Ø£Ù†...") Ø¨Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙˆØ§Ø¶Ø­Ø©.
    6. ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ù…Ø³ØªÙ‚Ù„Ø§Ù‹ ÙˆÙ‚Ø§Ø¦Ù…Ø§Ù‹ Ø¨Ø°Ø§ØªÙ‡.

    Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ù…Ø­Ø¯Ø«:
    """
    try:
        response = client.chat.completions.create(
            model="gpt-4o", messages=[{"role": "user", "content": summary_prompt}],
            temperature=0.2, max_tokens=300
        )
        summary = response.choices[0].message.content.strip()
        print(f"\n[SUMMARY UPDATED]: {summary}")
        return summary
    except Exception as e:
        print(f"Error creating summary: {e}")
        return previous_summary

def manage_conversation_history(conv_history, conv_summary, turns_since_summary):
    # This function now takes state as arguments and returns updated state
    turns_since_summary += 1
    print(f"[History Check]: Turns since last summary: {turns_since_summary}")

    if turns_since_summary >= SUMMARY_TRIGGER_COUNT:
        print(f"\n--- Managing History: Trigger count reached ---")
        actual_conversation = conv_history[1:]
        messages_to_keep_count = RECENT_TURNS_TO_KEEP * 2
        
        if len(actual_conversation) > messages_to_keep_count:
            messages_to_summarize = actual_conversation[:-messages_to_keep_count]
            recent_messages = actual_conversation[-messages_to_keep_count:]
            
            summary_text = ""
            for msg in messages_to_summarize:
                if msg['role'] in ['user', 'assistant']:
                    role = "Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…" if msg['role'] == 'user' else "Ø³ÙƒÙŠÙ†Ø©"
                    summary_text += f"{role}: {msg['content']}\n"

            new_summary = create_conversation_summary(conv_summary, summary_text)
            new_history = [
                conv_history[0],
                {"role": "system", "content": f"Ù…Ù„Ø®Øµ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø­ØªÙ‰ Ø§Ù„Ø¢Ù†: {new_summary}"}
            ] + recent_messages
            
            print("--- History Managed: Summary created and history pruned. ---")
            return new_history, new_summary, 0  # Reset counter

    return conv_history, conv_summary, turns_since_summary # Return unchanged state

def get_gpt_response(conv_history):
    # This function now takes history as an argument
    try:
        response = client.chat.completions.create(
            model="gpt-4o", messages=conv_history, temperature=0.7, max_tokens=100
        )
        gpt_response = response.choices[0].message.content.strip()
        print(f"[GPT-4o response]: {gpt_response}")
        return gpt_response
    except Exception as e:
        print(f"GPT-4o failed: {e}")
        return None

def get_claude_fallback_response(conv_history):
    # This function now takes history as an argument
    try:
        system_messages = [msg for msg in conv_history if msg['role'] == 'system']
        other_messages = [msg for msg in conv_history if msg['role'] != 'system']
        combined_system = "\n\n".join([msg['content'] for msg in system_messages])
        
        response = claude_client.messages.create(
            model="claude-opus-4-20250514", max_tokens=150, temperature=0.7,
            system=combined_system, messages=other_messages
        )
        claude_response = response.content[0].text.strip()
        print(f"[Claude fallback response]: {claude_response}")
        return claude_response
    except Exception as e:
        print(f"Claude failed: {e}")
        return "Ø¹Ø°Ø±Ù‹Ø§ØŒ Ø£ÙˆØ§Ø¬Ù‡ ØµØ¹ÙˆØ¨Ø© ÙÙ†ÙŠØ©. Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ù†Ø§ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ØŸ"


def validate_response_with_claude(gpt_response, user_query, conv_history):
    # This function now takes history as an argument
    validation_prompt = f"""
    Ø£Ù†Øª Ø®Ø¨ÙŠØ± ÙÙŠ ØªÙ‚ÙŠÙŠÙ… Ø§Ø³ØªØ¬Ø§Ø¨Ø§Øª Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„Ù†ÙØ³ÙŠ Ø¨Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ø¹Ù…Ø§Ù†ÙŠØ©. Ù…Ù‡Ù…ØªÙƒ Ù‡ÙŠ ØªÙ‚ÙŠÙŠÙ… Ø§Ø³ØªØ¬Ø§Ø¨Ø© GPT-4o ÙˆØªØ­Ø³ÙŠÙ†Ù‡Ø§ Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±.
Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„ØªÙ‚ÙŠÙŠÙ…:
â€¢ Ø¯Ù‚Ø© Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ø¹Ù…Ø§Ù†ÙŠØ© Ø§Ù„Ø£ØµÙŠÙ„Ø©
â€¢ Ø§Ù„Ø­Ø³Ø§Ø³ÙŠØ© Ø§Ù„Ø«Ù‚Ø§ÙÙŠØ© (Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø¥Ø³Ù„Ø§Ù…ÙŠØ©ØŒ Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ§Øª Ø§Ù„Ø£Ø³Ø±Ø©ØŒ Ø§Ù„Ø£Ø¹Ø±Ø§Ù Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠØ©)
â€¢ Ø§Ù„Ù…ØµØ·Ù„Ø­Ø§Øª Ø§Ù„Ø¹Ù„Ø§Ø¬ÙŠØ© Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø© ÙÙŠ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
â€¢ Ø§Ù„ØªÙƒØ§Ù…Ù„ Ø§Ù„Ø¯ÙŠÙ†ÙŠ/Ø§Ù„Ø±ÙˆØ­ÙŠ Ø¹Ù†Ø¯ Ø§Ù„Ø§Ù‚ØªØ¶Ø§Ø¡
â€¢ Ø§Ù„Ù…Ù„Ø§Ø¡Ù…Ø© Ø§Ù„Ø«Ù‚Ø§ÙÙŠØ© ÙˆÙÙ‡Ù… ÙˆØµÙ…Ø© Ø§Ù„ØµØ­Ø© Ø§Ù„Ù†ÙØ³ÙŠØ© ÙÙŠ Ø§Ù„Ø®Ù„ÙŠØ¬
â€¢ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø¹Ø§Ø·ÙÙŠ ÙˆØ§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ù„Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ø«Ù‚Ø§ÙÙŠØ©
â€¢ Ø§Ù„Ø­Ø³Ø§Ø³ÙŠØ© Ø§Ù„Ø¯ÙŠÙ†ÙŠØ© ÙˆØªÙƒØ§Ù…Ù„ Ø§Ù„Ø¥Ø±Ø´Ø§Ø¯ Ø§Ù„Ø¥Ø³Ù„Ø§Ù…ÙŠ

Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: "{user_query}"

Ø§Ø³ØªØ¬Ø§Ø¨Ø© GPT-4o: "{gpt_response}"

Ù‚Ù… Ø¨Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ù…Ø«Ù„ Ø§Ù„Ø¥Ù†Ø³Ø§Ù† ÙˆØªØ¬Ù†Ø¨ ØªÙ‚Ø¯ÙŠÙ… Ø±Ø¯ÙˆØ¯ Ø·ÙˆÙŠÙ„Ø©

Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª:
1. Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ø³ØªØ¬Ø§Ø¨Ø© GPT-4o Ù…Ù†Ø§Ø³Ø¨Ø© ØªÙ…Ø§Ù…Ø§Ù‹ ÙˆÙ„Ø§ ØªØ­ØªØ§Ø¬ ØªØ­Ø³ÙŠÙ†ØŒ Ø§ÙƒØªØ¨ ÙÙ‚Ø·: "good"
2. Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø¬ÙŠØ¯Ø© Ù„ÙƒÙ† ÙŠÙ…ÙƒÙ† ØªØ­Ø³ÙŠÙ†Ù‡Ø§ØŒ Ø§ÙƒØªØ¨ ÙÙ‚Ø· Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© (2-3 Ø¬Ù…Ù„) Ø§Ù„ØªÙŠ ØªÙÙƒÙ…Ù„ Ø§Ø³ØªØ¬Ø§Ø¨Ø© GPT-4o. 

Ù…Ù‡Ù… Ø¬Ø¯Ø§Ù‹: 
- Ù„Ø§ ØªÙƒØ±Ø± Ø£ÙŠ Ø´ÙŠØ¡ Ù…Ù† Ø§Ø³ØªØ¬Ø§Ø¨Ø© GPT-4o
- Ø§ÙƒØªØ¨ ÙÙ‚Ø· Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ø§Ù„ØªÙŠ ØªØ£ØªÙŠ Ø¨Ø¹Ø¯ Ø§Ø³ØªØ¬Ø§Ø¨Ø© GPT-4o
- ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ø§Ù„Ø¥Ø¶Ø§ÙØ© Ù…ØªÙ†Ø§Ø³Ù‚Ø© Ù…Ø¹ Ù†Ø¨Ø±Ø© ÙˆÙ…Ø­ØªÙˆÙ‰ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©
- ÙÙƒØ± ÙÙŠ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© ÙƒØ£Ù†Ù‡Ø§ Ø¬Ù…Ù„Ø© ÙˆØ§Ø­Ø¯Ø© Ø·ÙˆÙŠÙ„Ø©: GPT-4o + Ø¥Ø¶Ø§ÙØªÙƒ

Ù…Ø«Ø§Ù„:
Ø§Ø³ØªØ¬Ø§Ø¨Ø© GPT-4o: "Ø£Ù‡Ù„Ø§Ù‹ ÙˆØ³Ù‡Ù„Ø§Ù‹ØŒ ÙƒÙŠÙ Ø­Ø§Ù„Ùƒ Ø§Ù„ÙŠÙˆÙ…ØŸ"
Ø¥Ø¶Ø§ÙØªÙƒ Ø§Ù„ØµØ­ÙŠØ­Ø©: "Ø®Ø° Ø±Ø§Ø­ØªÙƒ ÙˆØªÙƒÙ„Ù… Ø¨Ø§Ù„ÙŠ ÙŠØ±ÙŠØ­Ùƒ."
Ø¥Ø¶Ø§ÙØªÙƒ Ø§Ù„Ø®Ø§Ø·Ø¦Ø©: "Ø£Ù‡Ù„Ø§Ù‹ ÙˆØ³Ù‡Ù„Ø§Ù‹ØŒ ÙƒÙŠÙ Ø­Ø§Ù„Ùƒ Ø§Ù„ÙŠÙˆÙ…ØŸ Ø®Ø° Ø±Ø§Ø­ØªÙƒ ÙˆØªÙƒÙ„Ù… Ø¨Ø§Ù„ÙŠ ÙŠØ±ÙŠØ­Ùƒ."

Ø§Ø³ØªØ¬Ø§Ø¨ØªÙƒ:
"""
    try:
        system_messages = [msg for msg in conv_history if msg['role'] == 'system']
        other_messages = [msg for msg in conv_history if msg['role'] != 'system']
        combined_system = "\n\n".join([msg['content'] for msg in system_messages])
        
        response = claude_client.messages.create(
            model="claude-opus-4-20250514", max_tokens=100, temperature=0.7,
            system=combined_system, messages=other_messages + [{"role": "user", "content": validation_prompt}]
        )
        validation_result = response.content[0].text.strip()
        print(f"[Claude validation]: {validation_result}")
        return validation_result
    except Exception as e:
        print(f"Claude validation failed: {e}")
        return "good"

# --- 3. GRADIO-SPECIFIC AUDIO AND ORCHESTRATION FUNCTIONS ---

def text_to_speech_to_memory(text):
    """
    REVISED: Converts text to speech and returns the audio data as bytes.
    This version correctly handles in-memory synthesis without audio output config.
    """
    print(f"--- Azure TTS (Optimized) ---")
    print(f"Attempting to synthesize text: '{text[:50]}...'")
    try:
        speech_config = speechsdk.SpeechConfig(subscription=AZURE_SPEECH_KEY, region=AZURE_SPEECH_REGION)
        speech_config.speech_synthesis_voice_name = AZURE_TTS_VOICE_NAME
        synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=None)
        
        result = synthesizer.speak_text_async(text).get()
        
        if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
            audio_data = result.audio_data
            print(f"Successfully synthesized {len(audio_data)} bytes of audio.")
            print("---------------------------")
            return audio_data
        else:
            cancellation = result.cancellation_details
            print(f"ERROR: Speech synthesis CANCELED: {cancellation.reason}")
            if cancellation.reason == speechsdk.CancellationReason.Error:
                print(f"Azure Error Details: {cancellation.error_details}")
            print("---------------------------")
            return None
            
    except Exception as e:
        print(f"CRITICAL ERROR in text_to_speech_to_memory: {e}")
        print("---------------------------")
        return None

def transcribe_audio_data(audio_data, sample_rate):
    """
    MODIFIED: Transcribes audio data with multi-language (Arabic/English) support.
    """
    if audio_data is None:
        return None
        
    try:
        # Azure expects bytes, so we convert the numpy array
        audio_bytes = audio_data.astype(np.int16).tobytes()

        speech_config = speechsdk.SpeechConfig(subscription=AZURE_SPEECH_KEY, region=AZURE_SPEECH_REGION)

        # 2. Create a configuration for auto-detecting the language from a list.
        auto_detect_source_language_config = speechsdk.AutoDetectSourceLanguageConfig(
            languages=[OMANI_ARABIC_LOCALE, ENGLISH_US_LOCALE]
        )
        # Create an audio stream from the bytes
        stream = speechsdk.audio.PushAudioInputStream(
            stream_format=speechsdk.audio.AudioStreamFormat(samples_per_second=sample_rate, bits_per_sample=16, channels=1)
        )
        stream.write(audio_bytes)
        stream.close() # Signal the end of the stream

        audio_config = speechsdk.audio.AudioConfig(stream=stream)
        
        # 3. Initialize the recognizer with the auto-detect config
        recognizer = speechsdk.SpeechRecognizer(
            speech_config=speech_config, 
            auto_detect_source_language_config=auto_detect_source_language_config,
            audio_config=audio_config
        )
        
        result = recognizer.recognize_once_async().get()
        
        if result.reason == speechsdk.ResultReason.RecognizedSpeech:
            recognized_text = result.text
            print(f"Ø£Ù†Øª (User): {recognized_text}")
            return recognized_text
        else:
            print(f"Speech recognition failed: {result.reason}")
            # If it fails, you can inspect the cancellation details
            if result.reason == speechsdk.ResultReason.Canceled:
                cancellation_details = result.cancellation_details
                print(f"Cancellation reason: {cancellation_details.reason}")
                if cancellation_details.reason == speechsdk.CancellationReason.Error:
                    print(f"Error details: {cancellation_details.error_details}")
            return None
    except Exception as e:
        print(f"An error occurred during speech-to-text: {e}")
        return None

def generate_bot_response_and_audio(conv_history):
    """
    REFACTORED: Generates the full bot response, including validation,
    and returns the final text and a single, combined audio file.
    """

    metrics = {}
    # Get initial response
    gpt_start_time = time.time()
    gpt_response = get_gpt_response(conv_history)
    metrics['2_gpt4o_latency'] = time.time() - gpt_start_time
    if gpt_response is None:
        claude_response = get_claude_fallback_response(conv_history)
        audio_data = text_to_speech_to_memory(claude_response)
        return claude_response, audio_data

    # Perform validation in parallel while generating audio for the first part
    user_query = conv_history[-1]['content']
    final_response_for_history = gpt_response
    
    parallel_start_time = time.time()

    with ThreadPoolExecutor(max_workers=2) as executor:
        # Start generating audio for the main response
        tts_start_time = time.time()
        tts_future = executor.submit(text_to_speech_to_memory, gpt_response)
        # Start validation
        claude_start_time = time.time()
        validation_future = executor.submit(validate_response_with_claude, gpt_response, user_query, conv_history)
        
        # Get results
        gpt_audio_data = tts_future.result()
        metrics['3a_azure_tts1_latency'] = time.time() - tts_start_time
        
        validation_result = validation_future.result()
        metrics['3b_claude_validation_latency'] = time.time() - claude_start_time

        metrics['3_parallel_block_latency'] = time.time() - parallel_start_time
        
        combined_audio_data = gpt_audio_data
        
        if validation_result.strip().lower() != "good":
            enhancement_tts_start_time = time.time()
            print("[Validation]: GPT response enhanced. Generating enhancement audio.")
            enhancement_audio_data = text_to_speech_to_memory(validation_result)
            metrics['4_azure_tts2_enhancement_latency'] = time.time() - enhancement_tts_start_time
            if gpt_audio_data and enhancement_audio_data:
                # Combine audio clips
                # The first 44 bytes of a WAV file are the header, we strip it from the second file
                combined_audio_data = gpt_audio_data + enhancement_audio_data[44:]
            
            final_response_for_history = f"{gpt_response} {validation_result}"

    return final_response_for_history, combined_audio_data, metrics


# --- 4. GRADIO INTERFACE AND MAIN APP LOGIC ---

def gradio_interface(mic_input, chat_history_state, summary_state, turns_state):
    """
    The main function called by Gradio on each interaction.
    """
    turn_start_time = time.time()
    current_turn_metrics = {}
    # 1. Transcribe User's Speech
    stt_start_time = time.time()
    user_text = transcribe_audio_data(mic_input[1], mic_input[0])
    current_turn_metrics['1_stt_latency'] = time.time() - stt_start_time
    
    if not user_text:
        # If transcription fails, just return the current state
        # Add a message to the user in the chat
        chat_history_state.append((None, "Sorry, I couldn't hear you. Please try again."))
        return chat_history_state, None, summary_state, turns_state

    # 2. Update Conversation History with User's Message
    chat_history_state.append((user_text))

    # Also update the internal message list for the LLM
    INITIAL_HISTORY.append({"role": "user", "content": user_text})

    # 3. Generate Bot's Response (Text and Audio)
    final_text, final_audio_data, response_gen_metrics = generate_bot_response_and_audio(INITIAL_HISTORY)
    current_turn_metrics.update(response_gen_metrics)
    
    # 4. Update History and State with Bot's Message
    INITIAL_HISTORY.append({"role": "assistant", "content": final_text})
    chat_history_state[-1] = (user_text, final_text)

    # 5. Manage history (summarization)
    summary_start_time = time.time()
    new_hist, new_summary, new_turns = manage_conversation_history(
        INITIAL_HISTORY, summary_state, turns_state
    )
    current_turn_metrics['6_summary_latency'] = time.time() - summary_start_time
    # Update the master history list with the potentially pruned version
    INITIAL_HISTORY[:] = new_hist

    current_turn_metrics['total_turn_latency'] = time.time() - turn_start_time

    # Log the metrics for this turn
    performance_log.append(current_turn_metrics)
    print("\n--- PERFORMANCE METRICS FOR THIS TURN ---")
    for key, value in current_turn_metrics.items():
        print(f"{key}: {value:.4f} seconds")
    print("-----------------------------------------\n")

    # 6. Return values to Gradio components
    # The audio component expects a tuple: (sample_rate, numpy_array)
    if final_audio_data:
        # Convert audio bytes back to numpy array for Gradio
        audio_np = np.frombuffer(final_audio_data, dtype=np.int16)
        bot_audio_output = (SAMPLE_RATE, audio_np)
    else:
        bot_audio_output = None

    return chat_history_state, bot_audio_output, new_summary, new_turns

# Build the Gradio UI
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("# ğŸ¤– Sakina - Omani AI Mental Health Companion")
    gr.Markdown("Click the 'Record from microphone' button and speak. The bot will listen and respond with voice.")

    # State variables to hold the conversation memory
    conversation_history_state = gr.State(INITIAL_HISTORY)
    conversation_summary_state = gr.State("")
    turns_since_last_summary_state = gr.State(0)

    with gr.Row():
        with gr.Column(scale=2):
            # The visual chatbot display (in Arabic)
            chatbot_display = gr.Chatbot(
                label="Conversation",
                rtl=True, # Right-to-Left for Arabic
                value=[(None, "Ø£Ù‡Ù„Ø§Ù‹ Ø¨ÙƒØŒ Ø£Ù†Ø§ Ø³ÙƒÙŠÙ†Ø©. ÙƒÙŠÙ Ø£Ù‚Ø¯Ø± Ø£Ø³Ø§Ø¹Ø¯Ùƒ Ø§Ù„ÙŠÙˆÙ…ØŸ")]
            )
            # The audio output for the bot's voice
            bot_audio_output = gr.Audio(
                label="Bot Response",
                autoplay=True,
                interactive=False,
                # Use visible=False to hide the player if you want a pure voice-only experience
                #visible=False
            )
        with gr.Column(scale=1):
            # The microphone input component
            mic_input = gr.Audio(
                label="Speak Here",
                sources=["microphone"],
                type="numpy" # Provides (sample_rate, numpy_array)
            )
    # Connect the components
    mic_input.stop_recording(
        fn=gradio_interface,
        inputs=[mic_input, chatbot_display, conversation_summary_state, turns_since_last_summary_state],
        outputs=[chatbot_display, bot_audio_output, conversation_summary_state, turns_since_last_summary_state]
    )

if __name__ == "__main__":
    # Add the initial welcome message to the history for the LLM
    INITIAL_HISTORY.append({"role": "assistant", "content": "Ø£Ù‡Ù„Ø§Ù‹ Ø¨ÙƒØŒ Ø£Ù†Ø§ Ø³ÙƒÙŠÙ†Ø©. ÙƒÙŠÙ Ø£Ù‚Ø¯Ø± Ø£Ø³Ø§Ø¹Ø¯Ùƒ Ø§Ù„ÙŠÙˆÙ…ØŸ"})
    demo.launch(debug=True)